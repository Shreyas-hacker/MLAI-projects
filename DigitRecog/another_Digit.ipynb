{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/shrey/OneDrive - Nanyang Technological University/Desktop/Dataset/trainingSet/trainingSet/FinalSet/\"\n",
    "path2 = \"C:/Users/shrey/OneDrive - Nanyang Technological University/Desktop/Dataset/testSet/final_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename class_name  class\n",
      "0  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          7      7\n",
      "1  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          3      3\n",
      "2  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          7      7\n",
      "3  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          3      3\n",
      "4  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          7      7\n",
      "60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filename        object\n",
       "class_name    category\n",
       "class             int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width, img_height = 28,28\n",
    "\n",
    "data = []\n",
    "for root,dirs,files in os.walk(path,topdown=True):\n",
    "    for name in files:\n",
    "        if '.jpeg' not in name:\n",
    "            continue\n",
    "        filename = os.path.abspath(os.path.join(root,name))\n",
    "        class_name = name[0]\n",
    "        data.append((filename,class_name))\n",
    "\n",
    "df = pd.DataFrame(data,columns=['filename','class_name'])\n",
    "df['class_name'] = df['class_name'].astype('category')\n",
    "df['class'] = df['class_name'].cat.codes\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.head())\n",
    "print(len(df))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename class_name  class\n",
      "0  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          4      4\n",
      "1  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          3      3\n",
      "2  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          8      8\n",
      "3  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          2      2\n",
      "4  C:\\Users\\shrey\\OneDrive - Nanyang Technologica...          9      9\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filename        object\n",
       "class_name    category\n",
       "class             int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for training set\n",
    "data2 = []\n",
    "for root,dirs,files in os.walk(path2,topdown=True):\n",
    "    for name in files:\n",
    "        if'.jpeg' not in name:\n",
    "            continue\n",
    "        filename = os.path.abspath(os.path.join(root,name))\n",
    "        class_name = name[10]\n",
    "        data2.append((filename, class_name))\n",
    "        \n",
    "df2 = pd.DataFrame(data2, columns=['filename','class_name'])\n",
    "df2['class_name'] = df2['class_name'].astype('category')\n",
    "df2['class'] = df2['class_name'].cat.codes\n",
    "\n",
    "#shuffle\n",
    "df2 = df2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(df2.head())\n",
    "print(len(df2))\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the pipeline for laoding and resizing the images\n",
    "\n",
    "#### Image Resizing and Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 28,28\n",
    "num_class = 10\n",
    "batch_size = 32\n",
    "\n",
    "def _parse_function(filename,label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string,channels=1)\n",
    "    image_resize = tf.image.resize(image_decoded,[img_width,img_height])\n",
    "    image_resized = tf.ensure_shape(image_resize,shape=(img_width,img_height,1))\n",
    "    label = tf.one_hot(label,num_class)\n",
    "    return image_resized,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((16, 28, 28, 1), (16, 10)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((tf.cast(df['filename'].values, tf.string), tf.cast(df['class'].values, tf.int32)))\n",
    "\n",
    "train_dataset = train_dataset.map(_parse_function)\n",
    "train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())\n",
    "train_dataset = train_dataset.shuffle(30)\n",
    "train_dataset = train_dataset.repeat(10)\n",
    "train_dataset = train_dataset.batch(16,drop_remainder=True)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28, 1), (None, 10)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = tf.data.Dataset.from_tensor_slices((tf.cast(df2['filename'].values, tf.string),\n",
    "                                                    tf.cast(df2['class'].values, tf.int32) ))\n",
    "valid_dataset = valid_dataset.map(_parse_function)\n",
    "valid_dataset = valid_dataset.apply(tf.data.experimental.ignore_errors())\n",
    "valid_dataset = valid_dataset.batch(16)\n",
    "\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "465c5b201858e001f3de52224df420302c022e48111b8e1e8429acbdd8e1444a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
